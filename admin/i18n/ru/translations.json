{
    "Assistant Settings": "Настройки Ассистента",
    "Give your personal assistant a name and describe its personality. Choose a model that should be used for your assistant.": "Дайте своему личному помощнику имя и опишите его личность. Выберите модель, которую следует использовать для вашего помощника.",
    "Name": "Имя",
    "Name for the Assistant": "Имя помощника",
    "Model": "Модель",
    "Which Model should be used": "Какую модель следует использовать",
    "Personality": "Личность",
    "Describe the personality of your assistant": "Опишите личность вашего помощника",
    "Friendly and helpful": "Дружелюбный и услужливый",
    "Language": "Язык",
    "Select the language that should be used by the assistant": "Выберите язык, который будет использовать помощник",
    "English": "Английский",
    "German": "немецкий",
    "Debug / Chain-of-Thought Output": "Отладка/вывод цепочки мыслей",
    "When activated the internal thought process of the assistant will be written to the response datapoint": "При активации внутренний мыслительный процесс помощника будет записан в точку данных ответа.",
    "Model Settings": "Настройки модели",
    "Select how many messages should be included for context retention. Temperature defines creativity/randomness of output from 0-1 where 0 is the most predictable output. Set how many tokens should be generated max for assistant responses.": "Выберите, сколько сообщений должно быть включено для сохранения контекста. Температура определяет креативность/случайность результата от 0 до 1, где 0 — наиболее предсказуемый результат. Установите максимальное количество токенов, которое должно быть сгенерировано для ответов помощника.",
    "Message History (Chat Mode)": "История сообщений (режим чата)",
    "If greater 0 previous messages will be included in the request so the tool will stay in context": "Если в запрос будет включено больше 0 предыдущих сообщений, инструмент останется в контексте.",
    "Temperature": "Температура",
    "Setting for creativity/consistency of the models response. (Leave at default if you are not sure!=": "Настройка креативности/последовательности ответов моделей. (Если вы не уверены, оставьте значение по умолчанию!=",
    "Max. Tokens": "Макс. Токены",
    "Limit the response of the tool to your desired amount of tokens.": "Ограничьте реакцию инструмента желаемым количеством токенов.",
    "Request Settings": "Запросить настройки",
    "Select if failed requests to the assistant should be retried and how long to wait between tries.": "Выберите, следует ли повторять неудачные запросы к помощнику и как долго ждать между попытками.",
    "Max. Retries": "Макс. Повторные попытки",
    "How many times should we retry if request to model fails": "Сколько раз мы должны повторить попытку, если запрос на моделирование не удался",
    "Retry Delay": "Задержка повтора",
    "How long to wait between retries": "Как долго ждать между повторными попытками",
    "Object access for assistant": "Доступ к объекту для помощника",
    "Please add the objects you want to use with the assistant. The assistant will be able to read and control these objects. You can use the button to import all states from your configured room sorting. Make sure to only include needed states to save tokens.": "Добавьте объекты, которые хотите использовать, с помощью помощника. Помощник сможет читать и управлять этими объектами. Вы можете использовать кнопку, чтобы импортировать все состояния из настроенной вами сортировки комнат. Обязательно включите только необходимые состояния для сохранения токенов.",
    "Import objects from enum.rooms": "Импортировать объекты из enum.rooms",
    "Do you really want to import objects from enum.rooms? Existing objects will be reset!": "Вы действительно хотите импортировать объекты из enum.rooms? Существующие объекты будут сброшены!",
    "Objects": "Объекты",
    "Active": "Активный",
    "Assistant can use Object": "Ассистент может использовать объект",
    "Sort": "Сортировать",
    "Room or sorting for Object": "Комната или сортировка объекта",
    "Object": "Объект",
    "Custom functions for assistant": "Пользовательские функции для помощника",
    "Define custom functions for the assistant. Make sure to add a good description for your functions so the assistant knows when to call your function. Each function needs a datapoint that starts the process and another datapoint that contains the result of your function.": "Определите пользовательские функции для помощника. Обязательно добавьте хорошее описание своих функций, чтобы помощник знал, когда вызывать вашу функцию. Каждой функции нужна точка данных, которая запускает процесс, и другая точка данных, содержащая результат вашей функции.",
    "Functions": "Функции",
    "Assistant can use this function": "Ассистент может использовать эту функцию",
    "A descriptive name for your function": "Описательное имя для вашей функции",
    "Description": "Описание",
    "Describe what your function does and how the data for the request should look. This is important for the assistant to understand your function.": "Опишите, что делает ваша функция и как должны выглядеть данные для запроса. Это важно, чтобы помощник понял ваши функции.",
    "Datapoint (Request)": "Точка данных (запрос)",
    "The datapoint that starts the request for the function": "Точка данных, которая запускает запрос функции",
    "Datapoint (Result)": "Точка данных (результат)",
    "The datapoint that contains the result of your function call (Has to be fulfilled in 60 Seconds!)": "Точка данных, содержащая результат вызова функции (должна быть выполнена за 60 секунд!)",
    "Please enter your Anthropic API Token to start using models like Opus, Haiku and Sonnet. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Введите свой токен Anthropic API, чтобы начать использовать такие модели, как Opus, Haiku и Sonnet. Если выпущены новые модели, вы можете просто добавить их в таблицу, чтобы начать использовать их с помощниками искусственного интеллекта.",
    "Settings": "Настройки",
    "API Token": "API-токен",
    "ERROR: column 'Model' must contain unique text": "ОШИБКА: столбец «Модель» должен содержать уникальный текст.",
    "Models": "Модели",
    "Model is active": "Модель активна",
    "Name of the Model": "Название модели",
    "Please enter your OpenAI API Token to start using models like Gpt4, Gpt4-o1, Gpt3-5. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Введите свой токен API OpenAI, чтобы начать использовать такие модели, как Gpt4, Gpt4-o1, Gpt3-5. Если выпущены новые модели, вы можете просто добавить их в таблицу, чтобы начать использовать их с помощниками искусственного интеллекта.",
    "Please enter your Perplexity API Token to start using the models. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Введите свой токен Perplexity API, чтобы начать использовать модели. Если выпущены новые модели, вы можете просто добавить их в таблицу, чтобы начать использовать их с помощниками искусственного интеллекта.",
    "Please enter your Openrouter API Token to start using the models. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Введите свой токен API Openrouter, чтобы начать использовать модели. Если выпущены новые модели, вы можете просто добавить их в таблицу, чтобы начать использовать их с помощниками искусственного интеллекта.",
    "You can use your custom or self hosted inference server to run open source models. The server needs to follow the rest api standards used by many providers, see examples below. Please make sure to add your used models by name to the table below.": "Вы можете использовать собственный или собственный сервер вывода для запуска моделей с открытым исходным кодом. Сервер должен соответствовать остальным стандартам API, используемым многими провайдерами, см. примеры ниже. Обязательно добавьте подержанные модели в таблицу ниже.",
    "Link to LM Studio": "Ссылка на студию LM",
    "Link to LocalAI": "Ссылка на LocalAI",
    "URL for Inference Server": "URL-адрес сервера вывода",
    "API Token for Inference Server": "Токен API для сервера вывода"
}
