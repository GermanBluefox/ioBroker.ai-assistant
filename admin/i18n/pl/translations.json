{
    "Assistant Settings": "Ustawienia Asystenta",
    "Give your personal assistant a name and describe its personality. Choose a model that should be used for your assistant.": "Nadaj swojemu osobistemu asystentowi imię i opisz jego osobowość. Wybierz model, który ma być zastosowany dla Twojego asystenta.",
    "Name": "Nazwa",
    "Name for the Assistant": "Imię dla Asystenta",
    "Model": "Model",
    "Which Model should be used": "Który model należy zastosować",
    "Personality": "Osobowość",
    "Describe the personality of your assistant": "Opisz osobowość swojego asystenta",
    "Friendly and helpful": "Przyjazny i pomocny",
    "Language": "Język",
    "Select the language that should be used by the assistant": "Wybierz język, jakim ma się posługiwać asystent",
    "English": "angielski",
    "German": "niemiecki",
    "Debug / Chain-of-Thought Output": "Debugowanie/wyjście łańcucha myślowego",
    "When activated the internal thought process of the assistant will be written to the response datapoint": "Po aktywacji wewnętrzny proces myślowy asystenta zostanie zapisany w punkcie danych odpowiedzi",
    "Model Settings": "Ustawienia modelu",
    "Select how many messages should be included for context retention. Temperature defines creativity/randomness of output from 0-1 where 0 is the most predictable output. Set how many tokens should be generated max for assistant responses.": "Wybierz, ile wiadomości ma zostać uwzględnionych w celu zachowania kontekstu. Temperatura określa kreatywność/losowość wyjścia w zakresie od 0 do 1, gdzie 0 jest najbardziej przewidywalnym wyjściem. Ustaw maksymalną liczbę tokenów generowanych dla odpowiedzi asystenta.",
    "Message History (Chat Mode)": "Historia wiadomości (tryb czatu)",
    "If greater 0 previous messages will be included in the request so the tool will stay in context": "Jeśli więcej niż 0, poprzednie wiadomości zostaną uwzględnione w żądaniu, więc narzędzie pozostanie w kontekście",
    "Temperature": "Temperatura",
    "Setting for creativity/consistency of the models response. (Leave at default if you are not sure!=": "Ustawienie kreatywności/spójności reakcji modeli. (Pozostaw ustawienie domyślne, jeśli nie jesteś pewien!=",
    "Max. Tokens": "Maks. Żetony",
    "Limit the response of the tool to your desired amount of tokens.": "Ogranicz reakcję narzędzia do żądanej liczby tokenów.",
    "Request Settings": "Ustawienia żądania",
    "Select if failed requests to the assistant should be retried and how long to wait between tries.": "Wybierz, czy należy ponawiać nieudane żądania kierowane do asystenta i jak długo należy czekać między próbami.",
    "Max. Retries": "Maks. Ponowne próby",
    "How many times should we retry if request to model fails": "Ile razy powinniśmy ponawiać próbę, jeśli żądanie modelu nie powiedzie się",
    "Retry Delay": "Opóźnienie ponownej próby",
    "How long to wait between retries": "Jak długo należy czekać między ponownymi próbami",
    "Object access for assistant": "Dostęp do obiektu dla asystenta",
    "Please add the objects you want to use with the assistant. The assistant will be able to read and control these objects. You can use the button to import all states from your configured room sorting. Make sure to only include needed states to save tokens.": "Dodaj obiekty, których chcesz używać z asystentem. Asystent będzie mógł czytać i sterować tymi obiektami. Za pomocą przycisku możesz zaimportować wszystkie stany ze skonfigurowanego sortowania pomieszczeń. Pamiętaj, aby uwzględnić tylko stany potrzebne do zapisania tokenów.",
    "Import objects from enum.rooms": "Importuj obiekty z enum.rooms",
    "Do you really want to import objects from enum.rooms? Existing objects will be reset!": "Czy na pewno chcesz importować obiekty z enum.rooms? Istniejące obiekty zostaną zresetowane!",
    "Objects": "Obiekty",
    "Active": "Aktywny",
    "Assistant can use Object": "Asystent może używać obiektu",
    "Sort": "Sortować",
    "Room or sorting for Object": "Pokój lub sortowanie dla obiektu",
    "Object": "Obiekt",
    "Custom functions for assistant": "Niestandardowe funkcje asystenta",
    "Define custom functions for the assistant. Make sure to add a good description for your functions so the assistant knows when to call your function. Each function needs a datapoint that starts the process and another datapoint that contains the result of your function.": "Zdefiniuj niestandardowe funkcje asystenta. Pamiętaj, aby dodać dobry opis swoich funkcji, aby asystent wiedział, kiedy wywołać Twoją funkcję. Każda funkcja potrzebuje punktu danych rozpoczynającego proces i innego punktu danych zawierającego wynik funkcji.",
    "Functions": "Funkcje",
    "Assistant can use this function": "Asystent może korzystać z tej funkcji",
    "A descriptive name for your function": "Opisowa nazwa funkcji",
    "Description": "Opis",
    "Describe what your function does and how the data for the request should look. This is important for the assistant to understand your function.": "Opisz, co robi Twoja funkcja i jak powinny wyglądać dane dla żądania. Jest to ważne, aby asystent rozumiał Twoją funkcję.",
    "Datapoint (Request)": "Punkt danych (żądanie)",
    "The datapoint that starts the request for the function": "Punkt danych, który rozpoczyna żądanie funkcji",
    "Datapoint (Result)": "Punkt danych (wynik)",
    "The datapoint that contains the result of your function call (Has to be fulfilled in 60 Seconds!)": "Punkt danych zawierający wynik wywołania funkcji (musi zostać wypełniony w 60 sekund!)",
    "Please enter your Anthropic API Token to start using models like Opus, Haiku and Sonnet. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Wprowadź swój token API Anthropic, aby rozpocząć korzystanie z modeli takich jak Opus, Haiku i Sonnet. Jeśli zostaną wydane nowe modele, możesz po prostu dodać je do tabeli, aby rozpocząć korzystanie z nich z asystentami AI.",
    "Settings": "Ustawienia",
    "API Token": "Token API",
    "ERROR: column 'Model' must contain unique text": "BŁĄD: kolumna „Model” musi zawierać unikalny tekst",
    "Models": "Modele",
    "Model is active": "Model jest aktywny",
    "Name of the Model": "Nazwa modelu",
    "Please enter your OpenAI API Token to start using models like Gpt4, Gpt4-o1, Gpt3-5. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Wprowadź swój token API OpenAI, aby rozpocząć korzystanie z modeli takich jak Gpt4, Gpt4-o1, Gpt3-5. Jeśli zostaną wydane nowe modele, możesz po prostu dodać je do tabeli, aby rozpocząć korzystanie z nich z asystentami AI.",
    "Please enter your Perplexity API Token to start using the models. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Aby rozpocząć korzystanie z modeli, wprowadź swój token API Perplexity. Jeśli zostaną wydane nowe modele, możesz po prostu dodać je do tabeli, aby rozpocząć korzystanie z nich z asystentami AI.",
    "Please enter your Openrouter API Token to start using the models. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Aby rozpocząć korzystanie z modeli, wprowadź swój token API Openrouter. Jeśli zostaną wydane nowe modele, możesz po prostu dodać je do tabeli, aby rozpocząć korzystanie z nich z asystentami AI.",
    "You can use your custom or self hosted inference server to run open source models. The server needs to follow the rest api standards used by many providers, see examples below. Please make sure to add your used models by name to the table below.": "Do uruchamiania modeli open source można używać niestandardowego lub hostowanego samodzielnie serwera wnioskowania. Serwer musi być zgodny z pozostałymi standardami API używanymi przez wielu dostawców, zobacz przykłady poniżej. Pamiętaj, aby dodać używane modele według nazwy do poniższej tabeli.",
    "Link to LM Studio": "Link do LM Studio",
    "Link to LocalAI": "Link do LocalAI",
    "URL for Inference Server": "Adres URL serwera wnioskowania",
    "API Token for Inference Server": "Token API dla serwera wnioskowania"
}
