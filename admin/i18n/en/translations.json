{
    "Assistant Settings": "Assistant Settings",
    "Give your personal assistant a name and describe its personality. Choose a model that should be used for your assistant.": "Give your personal assistant a name and describe its personality. Choose a model that should be used for your assistant.",
    "Name": "Name",
    "Name for the Assistant": "Name for the Assistant",
    "Model": "Model",
    "Which Model should be used": "Which Model should be used",
    "Personality": "Personality",
    "Describe the personality of your assistant": "Describe the personality of your assistant",
    "Friendly and helpful": "Friendly and helpful",
    "Language": "Language",
    "Select the language that should be used by the assistant": "Select the language that should be used by the assistant",
    "English": "English",
    "German": "German",
    "Debug / Chain-of-Thought Output": "Debug / Chain-of-Thought Output",
    "When activated the internal thought process of the assistant will be written to the response datapoint": "When activated the internal thought process of the assistant will be written to the response datapoint",
    "Model Settings": "Model Settings",
    "Select how many messages should be included for context retention. Temperature defines creativity/randomness of output from 0-1 where 0 is the most predictable output. Set how many tokens should be generated max for assistant responses.": "Select how many messages should be included for context retention. Temperature defines creativity/randomness of output from 0-1 where 0 is the most predictable output. Set how many tokens should be generated max for assistant responses.",
    "Message History (Chat Mode)": "Message History (Chat Mode)",
    "If greater 0 previous messages will be included in the request so the tool will stay in context": "If greater 0 previous messages will be included in the request so the tool will stay in context",
    "Temperature": "Temperature",
    "Setting for creativity/consistency of the models response. (Leave at default if you are not sure!=": "Setting for creativity/consistency of the models response. (Leave at default if you are not sure!=",
    "Max. Tokens": "Max. Tokens",
    "Limit the response of the tool to your desired amount of tokens.": "Limit the response of the tool to your desired amount of tokens.",
    "Request Settings": "Request Settings",
    "Select if failed requests to the assistant should be retried and how long to wait between tries.": "Select if failed requests to the assistant should be retried and how long to wait between tries.",
    "Max. Retries": "Max. Retries",
    "How many times should we retry if request to model fails": "How many times should we retry if request to model fails",
    "Retry Delay": "Retry Delay",
    "How long to wait between retries": "How long to wait between retries",
    "Object access for assistant": "Object access for assistant",
    "Please add the objects you want to use with the assistant. The assistant will be able to read and control these objects. You can use the button to import all states from your configured room sorting. Make sure to only include needed states to save tokens.": "Please add the objects you want to use with the assistant. The assistant will be able to read and control these objects. You can use the button to import all states from your configured room sorting. Make sure to only include needed states to save tokens.",
    "Import objects from enum.rooms": "Import objects from enum.rooms",
    "Do you really want to import objects from enum.rooms? Existing objects will be reset!": "Do you really want to import objects from enum.rooms? Existing objects will be reset!",
    "Objects": "Objects",
    "Active": "Active",
    "Assistant can use Object": "Assistant can use Object",
    "Sort": "Sort",
    "Room or sorting for Object": "Room or sorting for Object",
    "Object": "Object",
    "Custom functions for assistant": "Custom functions for assistant",
    "Define custom functions for the assistant. Make sure to add a good description for your functions so the assistant knows when to call your function. Each function needs a datapoint that starts the process and another datapoint that contains the result of your function.": "Define custom functions for the assistant. Make sure to add a good description for your functions so the assistant knows when to call your function. Each function needs a datapoint that starts the process and another datapoint that contains the result of your function.",
    "Functions": "Functions",
    "Assistant can use this function": "Assistant can use this function",
    "A descriptive name for your function": "A descriptive name for your function",
    "Description": "Description",
    "Describe what your function does and how the data for the request should look. This is important for the assistant to understand your function.": "Describe what your function does and how the data for the request should look. This is important for the assistant to understand your function.",
    "Datapoint (Request)": "Datapoint (Request)",
    "The datapoint that starts the request for the function": "The datapoint that starts the request for the function",
    "Datapoint (Result)": "Datapoint (Result)",
    "The datapoint that contains the result of your function call (Has to be fulfilled in 60 Seconds!)": "The datapoint that contains the result of your function call (Has to be fulfilled in 60 Seconds!)",
    "Please enter your Anthropic API Token to start using models like Opus, Haiku and Sonnet. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Please enter your Anthropic API Token to start using models like Opus, Haiku and Sonnet. If there are new models released you can simply add them in the table to start using them with ai assistants.",
    "Settings": "Settings",
    "API Token": "API Token",
    "ERROR: column 'Model' must contain unique text": "ERROR: column 'Model' must contain unique text",
    "Models": "Models",
    "Model is active": "Model is active",
    "Name of the Model": "Name of the Model",
    "Please enter your OpenAI API Token to start using models like Gpt4, Gpt4-o1, Gpt3-5. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Please enter your OpenAI API Token to start using models like Gpt4, Gpt4-o1, Gpt3-5. If there are new models released you can simply add them in the table to start using them with ai assistants.",
    "Please enter your Perplexity API Token to start using the models. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Please enter your Perplexity API Token to start using the models. If there are new models released you can simply add them in the table to start using them with ai assistants.",
    "Please enter your Openrouter API Token to start using the models. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Please enter your Openrouter API Token to start using the models. If there are new models released you can simply add them in the table to start using them with ai assistants.",
    "You can use your custom or self hosted inference server to run open source models. The server needs to follow the rest api standards used by many providers, see examples below. Please make sure to add your used models by name to the table below.": "You can use your custom or self hosted inference server to run open source models. The server needs to follow the rest api standards used by many providers, see examples below. Please make sure to add your used models by name to the table below.",
    "Link to LM Studio": "Link to LM Studio",
    "Link to LocalAI": "Link to LocalAI",
    "URL for Inference Server": "URL for Inference Server",
    "API Token for Inference Server": "API Token for Inference Server"
}
