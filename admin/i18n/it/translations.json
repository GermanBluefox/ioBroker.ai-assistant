{
    "Assistant Settings": "Impostazioni dell'assistente",
    "Give your personal assistant a name and describe its personality. Choose a model that should be used for your assistant.": "Dai un nome al tuo assistente personale e descrivi la sua personalità. Scegli un modello che dovrebbe essere utilizzato per il tuo assistente.",
    "Name": "Nome",
    "Name for the Assistant": "Nome per l'Assistente",
    "Model": "Modello",
    "Which Model should be used": "Quale modello dovrebbe essere utilizzato",
    "Personality": "Personalità",
    "Describe the personality of your assistant": "Descrivi la personalità del tuo assistente",
    "Friendly and helpful": "Cordiale e disponibile",
    "Language": "Lingua",
    "Select the language that should be used by the assistant": "Seleziona la lingua che dovrà essere utilizzata dall'assistente",
    "English": "Inglese",
    "German": "tedesco",
    "Debug / Chain-of-Thought Output": "Output di debug/catena di pensiero",
    "When activated the internal thought process of the assistant will be written to the response datapoint": "Una volta attivato, il processo di pensiero interno dell'assistente verrà scritto nel datapoint della risposta",
    "Model Settings": "Impostazioni del modello",
    "Select how many messages should be included for context retention. Temperature defines creativity/randomness of output from 0-1 where 0 is the most predictable output. Set how many tokens should be generated max for assistant responses.": "Seleziona il numero di messaggi da includere per la conservazione del contesto. La temperatura definisce la creatività/casualità dell'output da 0-1 dove 0 è l'output più prevedibile. Imposta il numero massimo di token da generare per le risposte dell'assistente.",
    "Message History (Chat Mode)": "Cronologia dei messaggi (modalità chat)",
    "If greater 0 previous messages will be included in the request so the tool will stay in context": "Se maggiore di 0 i messaggi precedenti verranno inclusi nella richiesta, lo strumento rimarrà nel contesto",
    "Temperature": "Temperatura",
    "Setting for creativity/consistency of the models response. (Leave at default if you are not sure!=": "Impostazione per creatività/coerenza della risposta dei modelli. (Lascia il valore predefinito se non sei sicuro!=",
    "Max. Tokens": "Massimo. Gettoni",
    "Limit the response of the tool to your desired amount of tokens.": "Limita la risposta dello strumento alla quantità di token desiderata.",
    "Request Settings": "Richiedi impostazioni",
    "Select if failed requests to the assistant should be retried and how long to wait between tries.": "Seleziona se le richieste non riuscite all'assistente devono essere ritentate e quanto tempo attendere tra un tentativo e l'altro.",
    "Max. Retries": "Massimo. Nuovi tentativi",
    "How many times should we retry if request to model fails": "Quante volte dovremmo riprovare se la richiesta al modello fallisce",
    "Retry Delay": "Ritardo riprova",
    "How long to wait between retries": "Quanto tempo attendere tra un nuovo tentativo e l'altro",
    "Object access for assistant": "Accesso agli oggetti per l'assistente",
    "Please add the objects you want to use with the assistant. The assistant will be able to read and control these objects. You can use the button to import all states from your configured room sorting. Make sure to only include needed states to save tokens.": "Aggiungi gli oggetti che desideri utilizzare con l'assistente. L'assistente sarà in grado di leggere e controllare questi oggetti. Puoi utilizzare il pulsante per importare tutti gli stati dall'ordinamento delle stanze configurato. Assicurati di includere solo gli stati necessari per salvare i token.",
    "Import objects from enum.rooms": "Importa oggetti da enum.rooms",
    "Do you really want to import objects from enum.rooms? Existing objects will be reset!": "Vuoi davvero importare oggetti da enum.rooms? Gli oggetti esistenti verranno ripristinati!",
    "Objects": "Oggetti",
    "Active": "Attivo",
    "Assistant can use Object": "L'assistente può utilizzare l'oggetto",
    "Sort": "Ordinare",
    "Room or sorting for Object": "Stanza o ordinamento per oggetto",
    "Object": "Oggetto",
    "Custom functions for assistant": "Funzioni personalizzate per l'assistente",
    "Define custom functions for the assistant. Make sure to add a good description for your functions so the assistant knows when to call your function. Each function needs a datapoint that starts the process and another datapoint that contains the result of your function.": "Definire funzioni personalizzate per l'assistente. Assicurati di aggiungere una buona descrizione per le tue funzioni in modo che l'assistente sappia quando chiamare la tua funzione. Ogni funzione necessita di un punto dati che avvii il processo e di un altro punto dati che contenga il risultato della funzione.",
    "Functions": "Funzioni",
    "Assistant can use this function": "L'assistente può utilizzare questa funzione",
    "A descriptive name for your function": "Un nome descrittivo per la tua funzione",
    "Description": "Descrizione",
    "Describe what your function does and how the data for the request should look. This is important for the assistant to understand your function.": "Descrivi cosa fa la tua funzione e come dovrebbero apparire i dati per la richiesta. Questo è importante affinché l'assistente comprenda la tua funzione.",
    "Datapoint (Request)": "Punto dati (richiesto)",
    "The datapoint that starts the request for the function": "Il punto dati che avvia la richiesta per la funzione",
    "Datapoint (Result)": "Punto dati (risultato)",
    "The datapoint that contains the result of your function call (Has to be fulfilled in 60 Seconds!)": "Il punto dati che contiene il risultato della chiamata di funzione (deve essere soddisfatto in 60 secondi!)",
    "Please enter your Anthropic API Token to start using models like Opus, Haiku and Sonnet. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Inserisci il tuo token API Anthropic per iniziare a utilizzare modelli come Opus, Haiku e Sonnet. Se vengono rilasciati nuovi modelli puoi semplicemente aggiungerli nella tabella per iniziare ad usarli con gli assistenti ai.",
    "Settings": "Impostazioni",
    "API Token": "Gettone API",
    "ERROR: column 'Model' must contain unique text": "ERRORE: la colonna \"Modello\" deve contenere testo univoco",
    "Models": "Modelli",
    "Model is active": "Il modello è attivo",
    "Name of the Model": "Nome del modello",
    "Please enter your OpenAI API Token to start using models like Gpt4, Gpt4-o1, Gpt3-5. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Inserisci il tuo token API OpenAI per iniziare a utilizzare modelli come Gpt4, Gpt4-o1, Gpt3-5. Se vengono rilasciati nuovi modelli puoi semplicemente aggiungerli nella tabella per iniziare ad usarli con gli assistenti ai.",
    "Please enter your Perplexity API Token to start using the models. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Inserisci il tuo token API Perplexity per iniziare a utilizzare i modelli. Se vengono rilasciati nuovi modelli puoi semplicemente aggiungerli nella tabella per iniziare ad usarli con gli assistenti ai.",
    "Please enter your Openrouter API Token to start using the models. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Inserisci il token API Openrouter per iniziare a utilizzare i modelli. Se vengono rilasciati nuovi modelli puoi semplicemente aggiungerli nella tabella per iniziare ad usarli con gli assistenti ai.",
    "You can use your custom or self hosted inference server to run open source models. The server needs to follow the rest api standards used by many providers, see examples below. Please make sure to add your used models by name to the table below.": "Puoi utilizzare il tuo server di inferenza personalizzato o ospitato autonomamente per eseguire modelli open source. Il server deve seguire gli altri standard API utilizzati da molti provider, vedere gli esempi di seguito. Assicurati di aggiungere i modelli usati per nome alla tabella seguente.",
    "Link to LM Studio": "Collegamento a LM Studio",
    "Link to LocalAI": "Collegamento a LocalAI",
    "URL for Inference Server": "URL per il server di inferenza",
    "API Token for Inference Server": "Token API per il server di inferenza"
}
